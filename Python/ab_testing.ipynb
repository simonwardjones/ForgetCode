{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Ultimate Guide To AB Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AB testing helps us understand change "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a product or service that works in a certain way we often want to make changes to improve this. When we make a change we want to be able to say that the impact is real and in the right direction. In order to be able to measure this change we can use AB testing.\n",
    "\n",
    "In an AB test we split the users into different groups; the control group stays with the same experience or product and then the other groups each receive a variation of this (often there is only one other variant). We then measure key metrics for each group and compare the results. AB testing can be used in many fields but is often used in product development.\n",
    "\n",
    "To make this more concrete for the rest of the article - imagine we are running a website and are looking to improve the conversion of users purchasing on our website. We want to run an AB test to see if changing the styling of a key product page increases the number of users converting. The users are randomly split into two groups, we show the control group the old website and we show the users in the variant group the modified styling. We run the test for a period of time and observe how many from each group go on to purchase - we then calculate the statistics to determine whether the conversion rate has improved for the new style.\n",
    "\n",
    "You can use AB testing for other metrics such as average spend but the analysis is a little different.\n",
    "\n",
    "When calculating the statistics for an AB test there are two main schools of thought - `Freqentist` and `Bayesian`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into the detail let's define the number of users entering the test as $n$ and the number of users who convert as $s$ (I chose s for success).\n",
    "\n",
    "We can then split users these between the two variants. We use $n_C$ and $n_V$ to represent the number of users in the control and variant respectively. We use $s_C$ and $s_V$ to represent the number of users who convert in the control and variant respectively. Note $n = n_C + n_V$ and $s = s_C + s_V$.\n",
    "\n",
    "Now we can write the conversion rate $c$ as $c = \\frac{s}{n}$ and for control $c_C = \\frac{s_C}{n_C}$ and for the variant $c_V = \\frac{s_V}{n_V}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist Vs Bayesian thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Freqentist` and `Bayesian` approaches to testing differ in how they calculate test statistics but also in how they think about the problem. It is worth describing these two different ways of thinking about testing before going into the calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequentist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Frequentists` view the `true` theoretical conversion rate as a fixed unique value - for instance in our example it could be 10%. This underlying value is also called the `population conversion rate` but it can't be directly observed as we can't realistically have everyone in the world try out our website. Instead we observe the `sample conversion rate` from the sample we do observe. This may be slightly different from the underlying conversion rate due to the randomness in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a `Bayesian` setting instead of considering the `population conversion rate` as a single unobservable value it is considered as a distribution. For instance it could be a distribution centered around 10% as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d138b131032e40bb94c9e3aa0cb6c891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'fill': 'tozeroy',\n",
       "              'opacity': 0.5,\n",
       "              'type': 'scatter',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bayesian_example_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Test Significance - the idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we understand how freqentist and bayesian frameworks view conversion rates we can explain how the test statistics are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequentist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a frequentist setting we initially assume that both the control and variant groups have the same underlying conversion rate (we assume that they are sampled from the same population). This assumption or hypothesis is known as the `null hypothesis` denoted $H_0$\n",
    "\n",
    "The `alternative hypothesis`, $H_1$ is just the opposite of the null hypothesis - that the underlying conversion rates are different.\n",
    "\n",
    "As we have initially assumed the underlying conversion rates are the same we expect the conversion rates of the control sample and variant sample to be close to each other and the underlying true value.\n",
    "\n",
    "Say if the underlying conversion rate was 10% (remember in practice we don't know this) then we would expect both the control and the variant to have roughly 10% of users convert under the null hypothesis.\n",
    "\n",
    "When sampling from a distribution where each user has a fixed probability $p$ of converting (the underlying conversion rate) then the conversion rate of a sample of users with size $n$ will tend to a normal distribution as we increase $n$. This is due to the central limit theorem.\n",
    "\n",
    "If the variant sample has an average conversion rate significantly different to the control we reject the null hypothesis.\n",
    "\n",
    "In order to decide whether the difference is significant we work out the $p$ value. The $p$ value is the probability of seeing a conversion rate in the variant at least as far away from the control conversion rate as we observed. If this $p$ is smaller than the preset significance value (also known as $\\alpha$ - often this is 5%) then we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A detailed look at the $p$ value\n",
    "\n",
    "We have said above that when we look at the conversion rate for a particular group (either variant or control) we are sampling from an underlying distribution. We know that the mean of a sample tends towards a normal distribution with a certain mean and variance.\n",
    "\n",
    "The mean can be estimated by the mean of the sample (i.e. the observed conversion rate)\n",
    "\n",
    "The standard deviation of the sampling distribution of the mean (also know as the standard error) is equal to the population standard deviation divided by the square root of the size of the sample.\n",
    "\n",
    "We can estimate the population standard deviation using the sample standard deviation.\n",
    "\n",
    "So we assume that the control sample conversion rate $\\mu(C,n_C)\\sim\\mathcal{N}(\\mu_C,\\sigma_C^2)$ where \n",
    "\n",
    "$$\\sigma_C^2 = \\frac{\\text{SD}_C^2}{n_C}$$\n",
    "\n",
    "where $\\text{SD}_C$ is the standard deviation of the control sample\n",
    "\n",
    "similarly we assume the variant conversion rate sample mean $\\mu(V,n_V)\\sim\\mathcal{N}(\\mu_V,\\sigma_V^2)$ where \n",
    "\n",
    "$$\\sigma_V^2 = \\frac{\\text{SD}_V^2}{n_V}$$\n",
    "\n",
    "where $\\text{SD}_V$ is the standard deviation of the variant sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in $\\mu(C,n_C) - \\mu(V,n_V)$ the difference between the two conversion rates. As we have assumed they are normally distributed we can say that the difference is also normally distributed\n",
    "\n",
    "$$\n",
    "\\mu(C,n_C) - \\mu(V,n_V) \\sim\\mathcal{N}(\\mu_C-\\mu_V,\\sigma_C^2+\\sigma_V^2) = \\mathcal{N}(\\mu_C-\\mu_V,\\frac{\\text{SD}_C^2}{n_C}+\\frac{\\text{SD}_V^2}{n_V})\n",
    "$$\n",
    "\n",
    "Under $H_0$ we assume $\\mu_C=\\mu_V$ hence\n",
    "\n",
    "$$\n",
    "\\mu(C,n_C) - \\mu(V,n_V) \\sim\\mathcal{N}(0,\\frac{\\text{SD}_C^2}{n_C}+\\frac{\\text{SD}_V^2}{n_V})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically we want to know the probability that difference was at least as extreme as we observed.\n",
    "I.e. \n",
    "\n",
    "$$\n",
    "P(|\\mu(C,n_C) - \\mu(V,n_V)| > \\mu_C - \\mu_V) = 2 * P(Z > \\frac{|\\mu_C - \\mu_V|}{\\sqrt{\\frac{\\text{SD}_C^2}{n_C}+\\frac{\\text{SD}_V^2}{n_V}}}   )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_conversion_rate = 0.2\n",
    "\n",
    "control_users = 100\n",
    "control_user_conversions = 21\n",
    "\n",
    "variant_users = 100\n",
    "variant_user_conversions = 25\n",
    "\n",
    "control_conversion_rate = control_user_conversions / control_users\n",
    "variant_conversion_rate = variant_user_conversions / variant_users\n",
    "control_variance = (control_conversion_rate * (1 - control_conversion_rate)) \n",
    "variant_variance = (variant_conversion_rate * (1 - variant_conversion_rate))\n",
    "diffence_variance = (control_variance / control_users) + (variant_variance / variant_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c79893de1aa44d78161470020efaff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'Distribution',\n",
       "              'type': 'scatter',\n",
       "              'uid': '78â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequentist_normal_difference(alpha=0.1, two_tale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Test Significance - the detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequentist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Test Significance - the detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequentist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can possibly go wrong ... ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequentist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from scipy.stats import distributions\n",
    "from scipy.stats import norm\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_example_distribution():\n",
    "    figure = go.FigureWidget()\n",
    "    \n",
    "    # Beta values to plot\n",
    "    n = 200\n",
    "    step = 1 / n\n",
    "    x = np.arange(0, 1, step)\n",
    "    beta = distributions.beta(a=10, b=100)\n",
    "    y = beta.pdf(x)\n",
    "\n",
    "    figure.add_scatter(x=x, y=y, fill='tozeroy',opacity=0.5)\n",
    "    \n",
    "    # labels\n",
    "    figure.layout.title = 'Example Conversion Rate Distribution'\n",
    "    figure.layout.xaxis.title = 'Conversion rate'\n",
    "    figure.layout.yaxis.title = 'Probability density'\n",
    "    figure.layout.xaxis.tickformat = '%'\n",
    "    figure.layout.yaxis.showticklabels = False\n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequentist_normal_difference(alpha = 0.05, two_tale = True):\n",
    "    difference_dist = norm(loc=control_conversion_rate, scale=diffence_variance ** 0.5)\n",
    "\n",
    "    start_prob = 0.0001\n",
    "    end_prob = 1 - start_prob\n",
    "    start, end  = difference_dist.ppf([start_prob, end_prob])\n",
    "\n",
    "    n_points=500\n",
    "    step = (end-start)/n_points\n",
    "    plot_conversion_rates = np.arange(start, end, step )\n",
    "    plot_conversion_rates_probs = difference_dist.pdf(plot_conversion_rates)\n",
    "\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_scatter(x=plot_conversion_rates, y=plot_conversion_rates_probs, name=\"Distribution\")\n",
    "    fig.layout.xaxis.title = 'Variant conversion rate'\n",
    "    fig.layout.yaxis.title = 'Probability density'\n",
    "\n",
    "    if two_tale:\n",
    "        alpha = alpha / 2\n",
    "    plot_alpha_right_x = np.arange(difference_dist.ppf(1 - alpha), end, step)\n",
    "    plot_alpha_right_y = difference_dist.pdf(plot_alpha_right_x)\n",
    "    plot_alpha_left_x = np.arange(start, difference_dist.ppf(alpha), step)\n",
    "    plot_alpha_left_y = difference_dist.pdf(plot_alpha_left_x)\n",
    "    right = fig.add_scatter(x=plot_alpha_right_x, y=plot_alpha_right_y, fill='tozeroy', name=f\"{alpha:.2%} prob\")\n",
    "    left = fig.add_scatter(x=plot_alpha_left_x, y=plot_alpha_left_y, fill='tozeroy', name=f\"{alpha:.2%} prob\",\n",
    "                           visible=two_tale)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "351.903px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
