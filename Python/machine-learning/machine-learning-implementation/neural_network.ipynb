{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "from graphviz import Digraph\n",
    "from IPython.display import display\n",
    "from plotly import graph_objects as go\n",
    "from scipy.special import logsumexp, expit\n",
    "from sklearn.datasets import load_boston, load_iris\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network mimics the brain as a series of nodes structured in layers. The network passes information between the layers depending on the layer's weights and the outputs from the previous layer.\n",
    "\n",
    "Let's assume we have data $x_1, x_2, \\dots x_m \\in \\mathbb{R}^{(n^0,1)}$ where m is the number of training examples and $n^0$ is the number of features in $x_i$\n",
    "Let's assume a classification problem with $y_1, y_2, \\dots y_m \\in{0,1}$\n",
    "\n",
    "Define $X$ with shape $(m, n^0)$ by stacking $x_1, x_2, \\dots x_m$ as\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "- & x_1^T & -\\\\\n",
    "- & x_2^T & -\\\\\n",
    "&\\vdots& \\\\\n",
    "- & x_m^T & -\n",
    "\\end{pmatrix}\t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the network with $L$ layers where the $L$'th layer is the output layer and layer $0$ is the input layer. The layers $1, 2, \\dots, L-1$ are known as the hidden layers. We define $n^l$ to be the number of nodes in layer $l$ for $l \\in 0, 1, \\dots, L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed forwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fully connected network the input to a node is equal to the sum of the output from each of the nodes in the previous layer multiplied by the weights for that layer plus a bias.  \n",
    "The output of the node is calculated by transforming the input using the activation function $g$. Various activation functions can be used but often it is chosen to be the sigmoid function, the relu function or the tanh function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For node $i$ in layer $l$ where $i\\in 1,\\dots n^l$ we define the net input $z^l_i$ and output $a^l_i$ as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "z^l_i&=\\sum^{n^{l-1}}_{j=0}W^l_{ij}a^{l-1}_j + \\beta^l_i \\quad i\\in 1,\\dots, n^l\\quad(1)\\\\\n",
    "a^l_i&=g(z^l_i) \\quad i\\in 1,\\dots, n^l\\quad(2)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note weight $W_{ij}^l$ goes from $a_j^{l-1} \\to z_i^{l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that the activation function $g$ is the sigmoid function then "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "g(x)&=\\frac{1}{1+e^{-x}}\\quad(3)\\\\\n",
    "g'(x)&=g(x)(1-g(x))\\quad(4)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward as vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "z^l &= W^l*a^{l-1} + \\beta^l\\quad(5)\\\\\n",
    "a^l &= g(z^l)\\quad(6)\\\\\n",
    "\\end{align}\\\\\n",
    "\\quad z^l,\\beta^l\\in \\mathbb{R}^{(n^l, 1)}\n",
    "\\quad a^{l-1}\\in \\mathbb{R}^{(n^{l-1}, 1)}\n",
    "\\quad W^{l-1} \\in \\mathbb{R}^{(n^{l}, n^{l-1})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward as matrices! Performing on multiple samples $x_i$ at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "Z^l &= W^l*A^{l-1} + B^l\\quad(7)\\\\\n",
    "A^l &= g(Z^l)\\quad(8)\\\\\n",
    "Z^1 &= W^1*X^{T} + B^l\\quad(9)\\\\\n",
    "\\end{align}\\\\\n",
    "\\quad Z^l, B^l\\in \\mathbb{R}^{(n^l, m)}\n",
    "\\quad a^{l-1}\\in \\mathbb{R}^{(n^{l-1}, m)}\n",
    "\\quad W^{l-1} \\in \\mathbb{R}^{(n^{l}, n^{l-1})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the columns of $Z^l$ and $A^l$ relate to $z^l$ and $a^l$  for the individual samples $x_k \\quad k\\in 1\\dots m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Z^l = \\begin{pmatrix}\n",
    "| & | & \\dots & |\\\\\n",
    "z^l_{x_1} & z^l_{x_2} & \\dots & z^l_{x_m}\\\\\n",
    "| & | & \\dots & |\n",
    "\\end{pmatrix}\n",
    "\\quad\n",
    "A^l = \\begin{pmatrix}\n",
    "| & | & \\dots & |\\\\\n",
    "a^l_{x_1} & a^l_{x_2} & \\dots & a^l_{x_m}\\\\\n",
    "| & | & \\dots & |\n",
    "\\end{pmatrix}\t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The m columns of $B^l$ are all copies of $\\beta^l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "B^l = \\begin{pmatrix}\n",
    "| & | & \\dots & |\\\\\n",
    "\\beta^l & \\beta^l & \\dots & \\beta^l\\\\\n",
    "| & | & \\dots & |\n",
    "\\end{pmatrix}\t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the binary classification context we can define the loss a.k.a cost function as the cross entropy (for one input data item $x_i$ and true output $y_i$ where $a^L_1$ is the model prediction of $y_i$ being in class 1 or $P(y\\in C_1)$ the loss is defined as follows:  \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = y_i\\log(a^L_1)+(1-y_i)\\log(1-a^L_{1})\\quad(10)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this is just the loss for one given sample $x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in all the other algorithms we seek to improve the model by changing the weights to reduce the loss. We do this by stepping the weights in the direction of the negative gradient of the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "W^l_{ij} &\\to W^l_{ij} + \\eta \\frac{\\partial \\mathcal{L}}{\\partial W^l_{ij}} \n",
    "\\quad i\\in 1,\\dots, n^l\n",
    "\\quad j\\in 1,\\dots, n^{l-1}\n",
    "\\quad l\\in 1,\\dots, L \\quad(11)\\\\\n",
    "\\beta^l_{i} &\\to \\beta^l_{i} + \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\beta^l_{i}} \n",
    "\\quad i\\in 1,\\dots, n^l\n",
    "\\quad l\\in 1,\\dots, L\\quad(12)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation is involved but ultimately comes down to calculating $\\frac{\\partial \\mathcal{L}}{\\partial W^l_{ij}} $ and $\\frac{\\partial \\mathcal{L}}{\\partial \\beta^l_{i}}$.  \n",
    "As the name back propagation implies we calculate the derivatives starting at the end or the \"right\" of the network and propagate the error backwards (using the chain rule).\n",
    "\n",
    "Above we have defined the loss for one training example. In this way we can updated the weights in a stochastic manner - or we can average the error across multiple samples and used batch gradient descent or just regular gradient descent if we average across all samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating $\\frac{\\partial \\mathcal{L}}{\\partial W^l_{ij}} $ and $\\frac{\\partial \\mathcal{L}}{\\partial \\beta^l_{i}}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for each layer $l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^l_{ij}} &= \n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z^l_{i}}\n",
    "\\frac{\\partial z^l_{i}}{\\partial W^l_{ij}}\n",
    ", \\quad\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\beta^l_{i}} = \n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z^l_{i}}\n",
    "\\frac{\\partial z^l_{i}}{\\partial \\beta^l_{i}}\\quad(13)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or defining $\\delta^l_i=\\frac{\\partial \\mathcal{L}}{\\partial z^l_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^l_{ij}} &= \n",
    "\\delta^l_i\n",
    "\\frac{\\partial z^l_{i}}{\\partial W^l_{ij}}\n",
    ", \\quad\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\beta^l_{i}} = \n",
    "\\delta^l_i\n",
    "\\frac{\\partial z^l_{i}}{\\partial \\beta^l_{i}}\\quad(14)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know ( by differentiating equation (1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial z^l_{i}}{\\partial W^l_{ij}} = a^{l-1}_j\n",
    ",\\quad\n",
    "\\frac{\\partial z^l_{i}}{\\partial \\beta^l_{i}} = 1\n",
    "\\quad(15)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in order to calculate the derivatives we must calculate $\\delta^l_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the very last layer (when there is only one node in the output layer) we can use the chain rule to write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^L_{1j}} &= \n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z^L_{1}}\n",
    "\\frac{\\partial z^L_{1}}{\\partial W^L_{1j}} = \n",
    "\\delta^L_i\n",
    "\\frac{\\partial z^L_{1}}{\\partial W^L_{1j}}\\quad(16)\\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^L_{1j}} &= \n",
    "\\frac{\\partial \\mathcal{L}}{\\partial a^L_{1}}\n",
    "\\frac{\\partial a^L_{1}}{\\partial z^L_{1}}\n",
    "\\frac{\\partial z^L_{1}}{\\partial W^L_{1j}}\\quad(17)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial a^L_{1}} &= \n",
    "\\frac{\\partial}{\\partial a^L_{1}}\\left(\n",
    "y_i\\log(a^L_1)+(1-y_i)\\log(1-a^L_{1})\n",
    "\\right)\\quad(18)\\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial a^L_{1}} &= \n",
    "\\frac{y_i}{a^L_1} + \\frac{1-y_i}{1-a^L_1}\\quad(19)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial a^L_{i}}{\\partial z^L_{i}} &=\n",
    "\\frac{\\partial}{\\partial z^L_{i}}\\left(\n",
    "g(z^L_{i})\n",
    "\\right) = \n",
    "\\frac{\\partial}{\\partial z^L_{i}}\\left(\n",
    "\\sigma(z^L_{i})\n",
    "\\right)\\\\\n",
    "&= \\sigma'(z^L_{i})\\\\\n",
    "&= \\sigma(z^L_{i})(1-\\sigma(z^L_{i}))\\\\\n",
    "&= a^L_{i}*(1-a^L_{i})\\quad(20)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on equations (19) and (20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\delta^L_1 = a^L_1 - y\\quad(21)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating $\\delta^l_i$ for $l<L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\delta^l_i &= \\frac{\\partial \\mathcal{L}}{\\partial z^l_{i}} \\\\\n",
    "\\delta^l_i &= \\frac{\\partial \\mathcal{L}}{\\partial a^l_{i}}\n",
    "\\frac{\\partial a^l_{i}}{\\partial z^l_{i}}\\\\\n",
    "\\delta^l_i &= \\left(\n",
    "\\sum_{j=1}^{n^{l+1}}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z^{l+1}_{j}}\n",
    "\\frac{\\partial z^{l+1}_{j}}{\\partial a^l_{i}}\n",
    "\\right)\n",
    "\\frac{\\partial a^l_{i}}{\\partial z^l_{i}}\\quad(22)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating (1) to get $\\frac{\\partial z^{l+1}_{j}}{\\partial a^l_{i}}$ and using equation (20) we can see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\delta^l_i &= \\left(\n",
    "\\sum_{j=1}^{n^{l+1}}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z^{l+1}_{j}}\n",
    "W_{ji}^{l+1}\n",
    "\\right)\n",
    "a^l_{i}*(1-a^l_{i})\\quad(23)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do it again using vectors/matrices instead of the scalar derivation above. Equations (11) and (12) become\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "W^l &\\to W^l - \\eta \\frac{\\partial \\mathcal{L}}{\\partial W^l} \n",
    "\\quad l\\in 1,\\dots, L \\quad(24)\\\\\n",
    "\\beta^l &\\to \\beta^l - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\beta^l} \n",
    "\\quad l\\in 1,\\dots, L\\quad(25)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (23) becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\delta^l &= (W^{l+1})^T\\delta^{l+1}\\odot a^l\\odot(1-a^l)\\quad(26)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^l}  = \\delta^l(a^{l-1})^T\\quad\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\beta^l}  = \\delta^l\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation as matrices! Performing on multiple samples $x_i$ at the same time using $X$. This is the batch approach to gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we define $Y$ with shape $(n^L, m) = (1, m)$ as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Y = \\begin{pmatrix}\n",
    "| & | & \\dots & |\\\\\n",
    "y_1 & y_2 & \\dots & y_m\\\\\n",
    "| & | & \\dots & |\n",
    "\\end{pmatrix}\t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L} = \\frac{1}{m}\\sum_{k=1}^{m}Y_{1k}\\log(A^L_{1k})+(1-Y_{1k})\\log(1-A^L_{1k})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define \n",
    "$$D^L = A^L - Y = \n",
    "\\begin{pmatrix}\n",
    "| & | & \\dots & |\\\\\n",
    "\\delta^l_{x_1} & \\delta^l_{x_2} & \\dots & \\delta^l_{x_m}\\\\\n",
    "| & | & \\dots & |\n",
    "\\end{pmatrix} \\in \\mathbb{R}^{(n^{L}, m)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "D^l = (W^{l+1})^TD^{l+1}\\odot A^l\\odot(\\mathbf{1}^{(n^l,m)}-A^l)\n",
    "\\quad\\in \\mathbb{R}^{(n^{l}, m)} \\quad l\\in 1\\dots L-1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the updates are \n",
    "$$\n",
    "\\begin{align}\n",
    "W^l &\\to W^l - \\frac{\\eta}{m}D^l(A^{l-1})^T\\\\\n",
    "\\beta^l &\\to \\beta^l - \\frac{\\eta}{m}D^l\\mathbf{1}^{(m,1)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can ignore the random logging metaclass\n",
    "\n",
    "class LoggedClassMeta(type):\n",
    "    def __init__(cls, name, bases, dct,**kwargs):\n",
    "        #  print(cls, name, bases, dct,kwargs)\n",
    "        if '_logging_level' in dct:\n",
    "            level = dct['_logging_level']\n",
    "        else:\n",
    "            level = logging.INFO\n",
    "        logger = logging.getLogger(name)\n",
    "        logger.setLevel(level)\n",
    "        cls.logger = logger\n",
    "\n",
    "        \n",
    "class LoggedClass(metaclass=LoggedClassMeta):\n",
    "    pass\n",
    "\n",
    "\n",
    "logging.basicConfig()\n",
    "\n",
    "\n",
    "class NeuralNetwork(LoggedClass):\n",
    "    _logging_level = logging.INFO\n",
    "    \n",
    "    def __init__(self, layer_sizes=[5,10,1], learning_rate=0.1):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        # L above\n",
    "        self.n_layers = len(layer_sizes) - 1\n",
    "        self.initialise_weights()\n",
    "        \n",
    "    def initialise_weights(self):\n",
    "        self.weight_matrices = [\n",
    "            np.random.normal(loc=0.0, scale=1.0, size=(n_l, n_l_minus_1))\n",
    "            for n_l, n_l_minus_1 in zip(self.layer_sizes[1:],self.layer_sizes)\n",
    "        ]\n",
    "        self.betas = [np.zeros(shape=(n_l, 1)) for n_l in self.layer_sizes[1:]]\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        m = X.shape[0]\n",
    "        layer_activations = [X.T]\n",
    "        for layer in range(self.n_layers):\n",
    "            A_layer_minus_1 = layer_activations[-1]\n",
    "            beta = self.betas[layer]\n",
    "            B = np.repeat(beta, m, axis=-1)\n",
    "            Z = self.weight_matrices[layer] @ A_layer_minus_1 + B\n",
    "            A = self.activation_function(Z)\n",
    "            layer_activations.append(A)\n",
    "            self.log_layer(layer, A_layer_minus_1, beta, B, Z, A)\n",
    "        self.layer_activations = layer_activations\n",
    "        return layer_activations[-1]\n",
    "\n",
    "    def back_propogation(self, X, Y):\n",
    "        assert X.shape[0] == Y.shape[1]\n",
    "        final_layer_error = self.layer_activations[-1] - Y\n",
    "        D_plus_1 = final_layer_error\n",
    "        # errors represent D matrices\n",
    "        errors = [D_plus_1]\n",
    "        for layer in range(self.n_layers - 2, -1, -1):\n",
    "            self.logger.debug(f'Calculating D_{layer + 1}')\n",
    "            A = self.layer_activations[layer + 1]\n",
    "            self.log_back_prop_layer(layer, A, D_plus_1)\n",
    "            D = (self.weight_matrices[layer + 1].T @ D_plus_1) * \\\n",
    "                A * (1 - A)\n",
    "            D_plus_1 = D\n",
    "            errors.insert(0, D)\n",
    "        self.errors= errors\n",
    "        self.update_weights()\n",
    "\n",
    "    def update_weights(self):\n",
    "        for layer in range(self.n_layers):\n",
    "            m = self.errors[0].shape[1]\n",
    "            d_L_d_W = (1 / m) * self.errors[layer] @ \\\n",
    "                self.layer_activations[layer].T\n",
    "            d_L_d_beta = (1 / m) * self.errors[layer].sum(axis=1)[:, None]\n",
    "            self.weight_matrices[layer] = self.weight_matrices[layer] - \\\n",
    "                self.learning_rate * d_L_d_W\n",
    "            if layer==0:\n",
    "                self.d_L_d_Ws.append(d_L_d_W.sum())\n",
    "            self.betas[layer] = self.betas[layer] - \\\n",
    "                self.learning_rate * d_L_d_beta\n",
    "            \n",
    "    def log_layer(self, layer, A_layer_minus_1, beta, B, Z, A):\n",
    "        self.logger.debug(\n",
    "            f'A_layer_minus_1 i.e. A_{layer} '\n",
    "            f'has shape {A_layer_minus_1.shape}')\n",
    "        self.logger.debug(f'beta_{layer + 1} has shape {beta.shape}')\n",
    "        self.logger.debug(f'B_{layer + 1} has shape {B.shape}')\n",
    "        self.logger.debug(f'Z_{layer + 1} has shape {Z.shape}')\n",
    "        self.logger.debug(f'A_{layer + 1} has shape {A.shape}')\n",
    "    \n",
    "    def log_back_prop_layer(self, layer,  A, D_plus_1):\n",
    "        self.logger.debug(\n",
    "            f'A_{layer + 1} has shape {A.shape}')\n",
    "        self.logger.debug(\n",
    "            f'W_{layer + 2} has shape '\n",
    "            f'{self.weight_matrices[layer + 1].shape}')\n",
    "        self.logger.debug(\n",
    "            f'D_{layer + 2} has shape {D_plus_1.shape}')\n",
    "\n",
    "    def activation_function(self, X):\n",
    "        return expit(X)\n",
    "    \n",
    "    def cost(self, Y):\n",
    "        cost = (-1 / m) * (\n",
    "            Y * np.log(self.layer_activations[-1]) + \\\n",
    "            (1 - Y) * np.log(1 - self.layer_activations[-1])\n",
    "        ).sum()\n",
    "        self.logger.debug(f'cost = {cost}')\n",
    "        self.costs.append(cost)\n",
    "    \n",
    "    def fit(self, X, Y, epochs=100):\n",
    "        self.costs = []\n",
    "        self.d_L_d_Ws = []\n",
    "        for epoch in range(epochs):\n",
    "            self.feed_forward(X)\n",
    "            self.cost(Y)\n",
    "            self.back_propogation(X, Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.round(self.feed_forward(X))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network on toy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Make fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = 20\n",
    "X = np.linspace(0, 10, m).reshape((m, 1))\n",
    "epsilon =  np.random.normal(scale=2, size=(m, 1))\n",
    "Y = X ** 2 + X + epsilon\n",
    "Y = (Y > 30).astype(int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit network and visualise cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = NeuralNetwork(\n",
    "    layer_sizes=[1,3,1],\n",
    "    learning_rate=0.3)\n",
    "neural_network.fit(X, Y, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd420858b06f408d9282db299a468591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter',\n",
       "              'uid': '61d5bdd2-42d5-4d17-96ff-da679fd6dbd4',\n",
       " …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget()\n",
    "fig.add_scatter(\n",
    "    x=list(range(len(neural_network.costs))),\n",
    "    y=neural_network.costs)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 with val 0.042, cost: 1.050\n",
      "iteration 100 with val 0.098, cost: 0.564\n",
      "iteration 200 with val 0.035, cost: 0.298\n",
      "iteration 300 with val 0.005, cost: 0.185\n",
      "iteration 400 with val 0.003, cost: 0.135\n"
     ]
    }
   ],
   "source": [
    "for i, (val,cost) in enumerate(zip(neural_network.d_L_d_Ws,neural_network.costs)):\n",
    "    if i % 100 == 0:\n",
    "        print(f'iteration {i} with val {abs(val):.3f}, cost: {cost:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Neural network binary classifier - Titanic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load titanic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_feather('../titanic/processed/X_train.feather')\n",
    "y_train = pd.read_feather('../titanic/processed/y_train.feather')\n",
    "X_test = pd.read_feather('../titanic/processed/X_test.feather')\n",
    "y_test = pd.read_feather('../titanic/processed/y_test.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Neural network model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 81.56%\n"
     ]
    }
   ],
   "source": [
    "titanic_nn = NeuralNetwork(layer_sizes=[30,50,1], learning_rate=0.5)\n",
    "titanic_nn.fit(X_train.values, y_train.values.T, epochs=400)\n",
    "y_pred = titanic_nn.predict(X_test.values)\n",
    "test_acc = (y_pred == y_test.values.flatten()).sum() / len(y_test)\n",
    "print(f'Test accuracy = {test_acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55483efcc8d4cd5b613de906e97ba57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter',\n",
       "              'uid': '26138041-37d9-4597-98b7-3e163ffae542',\n",
       " …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget()\n",
    "fig.add_scatter(\n",
    "    x=list(range(len(titanic_nn.costs))),\n",
    "    y=titanic_nn.costs)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TODO neural network classifier - Iris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  y\n",
       "0                6.1               2.8                4.7               1.2  1\n",
       "1                5.7               3.8                1.7               0.3  0\n",
       "2                7.7               2.6                6.9               2.3  2\n",
       "3                6.0               2.9                4.5               1.5  1\n",
       "4                6.8               2.8                4.8               1.4  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(iris_data['data'],columns=iris_data['feature_names'])\n",
    "iris_df['y'] = iris_data['target']\n",
    "iris_df = iris_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "iris_sample = iris_df.head(5)\n",
    "iris_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Fit neural network classifier and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decision_tree:Fitting tree 0\n",
      "INFO:decision_tree:Checking features [1 3]\n",
      "INFO:decision_tree:Splitting tree on feature_index 3 and feature_split_val 0.60\n",
      "INFO:decision_tree:Can't improve as node pure\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Checking features [1 1]\n",
      "INFO:decision_tree:Splitting tree on feature_index 1 and feature_split_val 2.40\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Fitting tree 1\n",
      "INFO:decision_tree:Checking features [0 0]\n",
      "INFO:decision_tree:Splitting tree on feature_index 0 and feature_split_val 5.40\n",
      "INFO:decision_tree:Checking features [0 2]\n",
      "INFO:decision_tree:Splitting tree on feature_index 2 and feature_split_val 1.90\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Checking features [1 2]\n",
      "INFO:decision_tree:Splitting tree on feature_index 2 and feature_split_val 4.70\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Fitting tree 2\n",
      "INFO:decision_tree:Checking features [1 2]\n",
      "INFO:decision_tree:Splitting tree on feature_index 2 and feature_split_val 1.90\n",
      "INFO:decision_tree:Can't improve as node pure\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Checking features [2 2]\n",
      "INFO:decision_tree:Splitting tree on feature_index 2 and feature_split_val 4.70\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"416pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 416.36 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-254 412.36,-254 412.36,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M229.91,-250C229.91,-250 94.69,-250 94.69,-250 88.69,-250 82.69,-244 82.69,-238 82.69,-238 82.69,-198 82.69,-198 82.69,-192 88.69,-186 94.69,-186 94.69,-186 229.91,-186 229.91,-186 235.91,-186 241.91,-192 241.91,-198 241.91,-198 241.91,-238 241.91,-238 241.91,-244 235.91,-250 229.91,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">petal width (cm) &lt;= 0.6</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 150</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.67</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [50 50 50]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.41,-143C140.41,-143 12.19,-143 12.19,-143 6.19,-143 0.19,-137 0.19,-131 0.19,-131 0.19,-105 0.19,-105 0.19,-99 6.19,-93 12.19,-93 12.19,-93 140.41,-93 140.41,-93 146.41,-93 152.41,-99 152.41,-105 152.41,-105 152.41,-131 152.41,-131 152.41,-137 146.41,-143 140.41,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.00</text>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [50 &#160;0 &#160;0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.09,-185.99C125.26,-174.78 114.14,-162.12 104.24,-150.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.84,-148.5 97.62,-143.29 101.58,-153.11 106.84,-148.5\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M314.41,-150C314.41,-150 182.2,-150 182.2,-150 176.2,-150 170.2,-144 170.2,-138 170.2,-138 170.2,-98 170.2,-98 170.2,-92 176.2,-86 182.2,-86 182.2,-86 314.41,-86 314.41,-86 320.41,-86 326.41,-92 326.41,-98 326.41,-98 326.41,-138 326.41,-138 326.41,-144 320.41,-150 314.41,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">sepal width (cm) &lt;= 2.4</text>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.50</text>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [ 0 50 50]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189.52,-185.99C197.36,-177.06 206.01,-167.19 214.22,-157.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"217.01,-159.97 220.98,-150.14 211.75,-155.35 217.01,-159.97\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.41,-50C222.41,-50 108.19,-50 108.19,-50 102.19,-50 96.19,-44 96.19,-38 96.19,-38 96.19,-12 96.19,-12 96.19,-6 102.19,0 108.19,0 108.19,0 222.41,0 222.41,0 228.41,0 234.41,-6 234.41,-12 234.41,-12 234.41,-38 234.41,-38 234.41,-44 228.41,-50 222.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"165.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"165.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.18</text>\n",
       "<text text-anchor=\"middle\" x=\"165.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [0 9 1]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219.97,-85.94C211.61,-76.77 202.45,-66.72 194.06,-57.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.55,-55.06 187.22,-50.03 191.38,-59.78 196.55,-55.06\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M396.41,-50C396.41,-50 264.2,-50 264.2,-50 258.2,-50 252.2,-44 252.2,-38 252.2,-38 252.2,-12 252.2,-12 252.2,-6 258.2,0 264.2,0 264.2,0 396.41,0 396.41,0 402.41,0 408.41,-6 408.41,-12 408.41,-12 408.41,-38 408.41,-38 408.41,-44 402.41,-50 396.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"330.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 90</text>\n",
       "<text text-anchor=\"middle\" x=\"330.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.50</text>\n",
       "<text text-anchor=\"middle\" x=\"330.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [ 0 41 49]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.3,-85.94C284.56,-76.77 293.61,-66.72 301.9,-57.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.56,-59.8 308.65,-50.03 299.36,-55.12 304.56,-59.8\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x110eecd50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_sample_vals = iris_sample.values\n",
    "\n",
    "# # for small sample\n",
    "# X = iris_sample_vals[:,:-1]\n",
    "# y = iris_sample_vals[:,-1]\n",
    "\n",
    "X = iris_df.values[:,:-1]\n",
    "y = iris_df.values[:,-1]\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "random_forest = RandomForest(n_classes=3, n_trees=3)\n",
    "random_forest.fit(X, y)\n",
    "\n",
    "feature_names = iris_data['feature_names']\n",
    "random_forest.render(tree_id=0, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Example prediction on Iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03875969, 0.77235142, 0.18888889],\n",
       "       [0.70542636, 0.29457364, 0.        ],\n",
       "       [0.        , 0.22457912, 0.77542088],\n",
       "       [0.03875969, 0.77235142, 0.18888889]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.predict_proba(X[0:4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0,\n",
       "       0, 2, 1, 2, 2, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 1,\n",
       "       1, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2,\n",
       "       0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0,\n",
       "       0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1,\n",
       "       1, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2,\n",
       "       0, 2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TODO neural network regressor - Boston housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load Boston housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "0  0.09178   0.0   4.05   0.0  0.510  6.416  84.1  2.6463   5.0  296.0   \n",
       "1  0.05644  40.0   6.41   1.0  0.447  6.758  32.9  4.0776   4.0  254.0   \n",
       "2  0.10574   0.0  27.74   0.0  0.609  5.983  98.8  1.8681   4.0  711.0   \n",
       "3  0.09164   0.0  10.81   0.0  0.413  6.065   7.8  5.2873   4.0  305.0   \n",
       "4  5.09017   0.0  18.10   0.0  0.713  6.297  91.8  2.3682  24.0  666.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT     y  \n",
       "0     16.6  395.50   9.04  23.6  \n",
       "1     17.6  396.90   3.53  32.4  \n",
       "2     20.1  390.11  18.07  13.6  \n",
       "3     19.2  390.91   5.52  22.8  \n",
       "4     20.2  385.09  17.27  16.1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data = load_boston()\n",
    "boston_df = pd.DataFrame(boston_data['data'], columns=boston_data['feature_names'])\n",
    "boston_df['y'] = boston_data['target']\n",
    "boston_df = boston_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "boston_sample = boston_df.head(5)\n",
    "boston_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fit neural network on Boston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"538pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 538.28 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-254 534.28,-254 534.28,4 -4,4\"/>\n",
       "<!-- 363 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>363</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.42,-250C312.42,-250 216.86,-250 216.86,-250 210.86,-250 204.86,-244 204.86,-238 204.86,-238 204.86,-198 204.86,-198 204.86,-192 210.86,-186 216.86,-186 216.86,-186 312.42,-186 312.42,-186 318.42,-186 324.42,-192 324.42,-198 324.42,-198 324.42,-238 324.42,-238 324.42,-244 318.42,-250 312.42,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">NOX &lt;= 0.668</text>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 404</text>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 89.96</text>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 22.94</text>\n",
       "</g>\n",
       "<!-- 364 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>364</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.42,-150C244.42,-150 148.86,-150 148.86,-150 142.86,-150 136.86,-144 136.86,-138 136.86,-138 136.86,-98 136.86,-98 136.86,-92 142.86,-86 148.86,-86 148.86,-86 244.42,-86 244.42,-86 250.42,-86 256.42,-92 256.42,-98 256.42,-98 256.42,-138 256.42,-138 256.42,-144 250.42,-150 244.42,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">LSTAT &lt;= 5.39</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 327</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 81.66</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 25.08</text>\n",
       "</g>\n",
       "<!-- 363&#45;&gt;364 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>363&#45;&gt;364</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.12,-185.99C237.05,-177.23 230.35,-167.58 223.98,-158.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.82,-156.36 218.25,-150.14 221.07,-160.35 226.82,-156.36\"/>\n",
       "</g>\n",
       "<!-- 365 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>365</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M381.42,-150C381.42,-150 285.86,-150 285.86,-150 279.86,-150 273.86,-144 273.86,-138 273.86,-138 273.86,-98 273.86,-98 273.86,-92 279.86,-86 285.86,-86 285.86,-86 381.42,-86 381.42,-86 387.42,-86 393.42,-92 393.42,-98 393.42,-98 393.42,-138 393.42,-138 393.42,-144 387.42,-150 381.42,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">CHAS &lt;= 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 77</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 23.40</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 13.86</text>\n",
       "</g>\n",
       "<!-- 363&#45;&gt;365 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>363&#45;&gt;365</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.47,-185.99C292.64,-177.23 299.43,-167.58 305.9,-158.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.82,-160.33 311.71,-150.14 303.09,-156.3 308.82,-160.33\"/>\n",
       "</g>\n",
       "<!-- 366 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>366</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.42,-50C107.42,-50 11.86,-50 11.86,-50 5.86,-50 -0.14,-44 -0.14,-38 -0.14,-38 -0.14,-12 -0.14,-12 -0.14,-6 5.86,0 11.86,0 11.86,0 107.42,0 107.42,0 113.42,0 119.42,-6 119.42,-12 119.42,-12 119.42,-38 119.42,-38 119.42,-44 113.42,-50 107.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"59.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 69</text>\n",
       "<text text-anchor=\"middle\" x=\"59.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 74.32</text>\n",
       "<text text-anchor=\"middle\" x=\"59.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 36.73</text>\n",
       "</g>\n",
       "<!-- 364&#45;&gt;366 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>364&#45;&gt;366</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149.87,-85.94C135.1,-76.12 118.82,-65.31 104.21,-55.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.08,-52.65 95.82,-50.03 102.21,-58.48 106.08,-52.65\"/>\n",
       "</g>\n",
       "<!-- 367 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>367</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.42,-50C244.42,-50 148.86,-50 148.86,-50 142.86,-50 136.86,-44 136.86,-38 136.86,-38 136.86,-12 136.86,-12 136.86,-6 142.86,0 148.86,0 148.86,0 244.42,0 244.42,0 250.42,0 256.42,-6 256.42,-12 256.42,-12 256.42,-38 256.42,-38 256.42,-44 250.42,-50 244.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 258</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 37.60</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 21.96</text>\n",
       "</g>\n",
       "<!-- 364&#45;&gt;367 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>364&#45;&gt;367</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.64,-85.94C196.64,-77.68 196.64,-68.72 196.64,-60.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.14,-60.03 196.64,-50.03 193.14,-60.03 200.14,-60.03\"/>\n",
       "</g>\n",
       "<!-- 368 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M381.42,-50C381.42,-50 285.86,-50 285.86,-50 279.86,-50 273.86,-44 273.86,-38 273.86,-38 273.86,-12 273.86,-12 273.86,-6 279.86,0 285.86,0 285.86,0 381.42,0 381.42,0 387.42,0 393.42,-6 393.42,-12 393.42,-12 393.42,-38 393.42,-38 393.42,-44 387.42,-50 381.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 70</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 22.43</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 13.42</text>\n",
       "</g>\n",
       "<!-- 365&#45;&gt;368 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>365&#45;&gt;368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M333.64,-85.94C333.64,-77.68 333.64,-68.72 333.64,-60.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"337.14,-60.03 333.64,-50.03 330.14,-60.03 337.14,-60.03\"/>\n",
       "</g>\n",
       "<!-- 369 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>369</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M518.42,-50C518.42,-50 422.86,-50 422.86,-50 416.86,-50 410.86,-44 410.86,-38 410.86,-38 410.86,-12 410.86,-12 410.86,-6 416.86,0 422.86,0 422.86,0 518.42,0 518.42,0 524.42,0 530.42,-6 530.42,-12 530.42,-12 530.42,-38 530.42,-38 530.42,-44 524.42,-50 518.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 7</text>\n",
       "<text text-anchor=\"middle\" x=\"470.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 12.34</text>\n",
       "<text text-anchor=\"middle\" x=\"470.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 18.20</text>\n",
       "</g>\n",
       "<!-- 365&#45;&gt;369 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>365&#45;&gt;369</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M380.4,-85.94C395.18,-76.12 411.46,-65.31 426.07,-55.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"428.07,-58.48 434.46,-50.03 424.2,-52.65 428.07,-58.48\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x123d9f990>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_df.values[:,:-1]\n",
    "y = boston_df.values[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "boston_random_forest = RandomForest(\n",
    "    impurity='mse',\n",
    "    is_classifier=False,\n",
    "    n_trees=100,\n",
    "    max_depth=2)\n",
    "boston_random_forest.fit(X_train, y_train)\n",
    "\n",
    "boston_feature_names = boston_data['feature_names']\n",
    "boston_random_forest.render(tree_id=0,feature_names=boston_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random forest accuracy on Boston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (R2 score) = 61.39%\n"
     ]
    }
   ],
   "source": [
    "y_pred = boston_random_forest.predict(X_test)\n",
    "test_acc = r2_score(y_test, y_pred)\n",
    "print(f'Test accuracy (R2 score) = {test_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "430.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
