{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# machine_learning_implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a notebook for the detail - both mathematically and of a raw Ward-Jones python implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "from plotly import graph_objects as go\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The linear model (or line of best fit in 2D) aims to describe the continuous y vairable a.k.a the target variable (e.g. house prices) as a linear combination of features (e.g. square footage / number of bedrooms) the features are also refered to as the design matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y}&=\\beta_0x_0+\\cdots+\\beta_nx_n\\quad &n\\in \\mathbb{N}, x_o = 1 \\\\\n",
    "\\hat{y}&=\\sum^{n}_{i=0}\\beta_ix_i \\\\\n",
    "\\hat{y}&=\\mathbf{\\boldsymbol{\\beta}^Tx}\\quad&\\boldsymbol{\\beta},\\mathbf{x}\\in\\mathbb{R}^{n\\times1}\\\\\n",
    "\\hat{y}&=g(\\boldsymbol{\\beta}^T\\mathbf{x})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "where g, the activation function, is the identidy in linear regression  \n",
    "\n",
    "We define the cost function as half of the mean square error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "J(\\boldsymbol{\\beta})\n",
    "&= \\frac{1}{2m}\\sum^{m}_{j=1}\\left(\n",
    "y^j-\\hat{y}^j\n",
    "\\right)^2,\\quad m\\in \\mathbb{N} \\text{ is the number of training samples}\\\\\n",
    "&= \\frac{1}{2m}\\sum^{m}_{j=1}\\left(\n",
    "y^j-g(\\boldsymbol{\\beta}^T\\mathbf{x}^j)\n",
    "\\right)^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to differentiate the cost function i.e. find the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial\\beta_k}\\left(\\boldsymbol{\\beta}\\right) &= \\frac{\\partial}{\\partial\\beta_k}\\left(\n",
    "\\frac{1}{2m}\\sum^{m}_{j=1}\\left(\n",
    "y^j-g(\\boldsymbol{\\beta}^T\\mathbf{x}^j)\\right)^2\n",
    "\\right)\\\\\n",
    "&= \\frac{\\partial}{\\partial\\beta_k}\\left(\n",
    "\\frac{1}{2m}\\sum^{m}_{j=1}\n",
    "\\left(\n",
    "y^j-\\sum^{n}_{i=0}\\beta_ix_i^j\n",
    "\\right)^2\n",
    "\\right)\\\\\n",
    "&=\n",
    "\\frac{1}{m}\\sum^{m}_{j=1}\n",
    "\\left(\n",
    "y^j-\\sum^{n}_{i=0}\\beta_ix_i^j\n",
    "\\right)(-x^j_k)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "hence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\beta}} J\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "       \\frac{\\partial J}{\\partial\\beta_1} \\\\\n",
    "       \\vdots \\\\\n",
    "       \\frac{\\partial J}{\\partial\\beta_n}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "       -\\frac{1}{m}\\sum^{m}_{j=1}\n",
    "           \\left(y^j-\\sum^{n}_{i=0}\\beta_ix_i^j\\right)x^j_1\\\\\n",
    "       \\vdots \\\\\n",
    "       -\\frac{1}{m}\\sum^{m}_{j=1}\n",
    "           \\left(y^j-\\sum^{n}_{i=0}\\beta_ix_i^j\\right)x^j_n\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define the design matrix and column representation of y. Here each row of X and y are training examples hence there are m rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\\mathbf{X}\\in\\mathbb{R}^{m\\times n},\n",
    "\\quad \\mathbf{y}\\in\\mathbb{R}^{m\\times 1}\n",
    "$$\n",
    "\n",
    "$$\\\\\n",
    "\\mathbf{X}=\\begin{bmatrix}\n",
    "       \\dots & (\\mathbf{x}^1)^T & \\dots\\\\\n",
    "       \\dots & (\\mathbf{x}^2)^T & \\dots\\\\\n",
    "       \\dots & \\vdots  & \\dots\\\\\n",
    "       \\dots & (\\mathbf{x}^m)^T & \\dots\n",
    "\\end{bmatrix}\\quad\n",
    "\\mathbf{y}=\\begin{bmatrix}\n",
    "    y_1\\\\y_2\\\\\\vdots\\\\y_m\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\boldsymbol{\\beta}} J\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "       -\\frac{1}{m}\\sum^{m}_{j=1}\n",
    "           \\left(y^j-\\sum^{n}_{i=0}\\beta_ix_i^j\\right)x^j_1\\\\\n",
    "       \\vdots \\\\\n",
    "       -\\frac{1}{m}\\sum^{m}_{j=1}\n",
    "           \\left(y^j-\\sum^{n}_{i=0}\\beta_ix_i^j\\right)x^j_n\\\\\n",
    "\\end{bmatrix}\n",
    "=-\\frac{1}{m}\n",
    "\\begin{bmatrix}\n",
    "       \\sum^{m}_{j=1}y^jx^j_1\\\\\n",
    "       \\vdots \\\\\n",
    "       \\sum^{m}_{j=1}y^jx^j_n\\\\\n",
    "\\end{bmatrix}+\n",
    "\\frac{1}{m}\n",
    "\\begin{bmatrix}\n",
    "       \\sum^{m}_{j=0}\\sum^{n}_{i=0}\\beta_ix_i^jx^j_1\\\\\n",
    "       \\vdots \\\\\n",
    "       \\sum^{m}_{j=0}\\sum^{n}_{i=0}\\beta_ix_i^jx^j_n\n",
    "\\end{bmatrix}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\boldsymbol{\\beta}} J\n",
    "&=\\frac{1}{m}\\left(\n",
    "\\mathbf{X}^T\\mathbf{X}\\mathbf{\\boldsymbol{\\beta}}-\\mathbf{X}^T\\mathbf{y}\n",
    "\\right)\\\\\n",
    "&=\\frac{1}{m}\\mathbf{X}^T\\left(\n",
    "\\mathbf{X}\\mathbf{\\boldsymbol{\\beta}}-\\mathbf{y}\n",
    "\\right)\\\\\n",
    "&=\\frac{1}{m}\\mathbf{X}^T\\left(\n",
    "\\mathbf{\\hat{y}}-\\mathbf{y}\n",
    "\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\mathbf{\\hat{y}} = \\mathbf{X}\\mathbf{\\boldsymbol{\\beta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We could have derived the same thing using matrix calculus - noting the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "J(\\boldsymbol{\\beta}) &= \\frac{1}{2m}\\sum^{m}_{j=1}\\left(\n",
    "y^j-g(\\boldsymbol{\\beta}^T\\mathbf{x}^j)\n",
    "\\right)^2\\\\\n",
    "&= \\frac{1}{2m}\\left(\n",
    "\\mathbf{y}-\\mathbf{\\hat{y}}\n",
    "\\right)^T\n",
    "\\left(\n",
    "\\mathbf{y}-\\mathbf{\\hat{y}}\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2m}\\left(\n",
    "\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta}\n",
    "\\right)^T\n",
    "\\left(\n",
    "\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta}\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2m}\\left(\n",
    "\\mathbf{y}^T\\mathbf{y}\n",
    "-\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y}\n",
    "-\\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta}\n",
    "+\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n",
    "\\right)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial\\mathbf{\\boldsymbol{\\beta}}}\n",
    "\\left(\n",
    "A^T\\boldsymbol{\\beta}\n",
    "\\right) = A,\\quad \\forall A\\in\\mathbb{R}^{n\\times1}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial\\mathbf{\\boldsymbol{\\beta}}}\n",
    "\\left(\n",
    "\\boldsymbol{\\beta}^TA\\boldsymbol{\\beta}\n",
    "\\right) = 2A\\boldsymbol{\\beta},\\quad \\forall A\\in\\mathbb{R}^{m\\times n}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\beta}}J=\\frac{1}{m}\\left(\n",
    "\\mathbf{X}^T\\mathbf{X}\\mathbf{\\boldsymbol{\\beta}}-\\mathbf{X}^T\\mathbf{y}\n",
    "\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### make fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = 100\n",
    "x0 = np.ones(shape=(m, 1))\n",
    "x1 = np.linspace(0, 10, m).reshape(-1, 1)\n",
    "X = np.column_stack((x0, x1))\n",
    "\n",
    "# let y = 0.5 * x + 1 + epsilon\n",
    "epsilon =  np.random.normal(scale=0.5, size=(m, 1))\n",
    "y = x1 + 1 + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006930fa376541d6936a89a3c23b2f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'name': 'linear data + noise',\n",
       "              'ty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget()\n",
    "fig = fig.add_scatter(\n",
    "    x=X[:,1],\n",
    "    y=y[:,0],\n",
    "    mode='markers',\n",
    "    name='linear data + noise')\n",
    "fig.layout.title = 'Fake linear data with noise'\n",
    "fig.layout.xaxis.title = 'x1'\n",
    "fig.layout.yaxis.title = 'y'\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    \n",
    "    def __init__(self, learning_rate=0.05):\n",
    "        self.learning_rate = learning_rate\n",
    "        print('Creating linear model instance')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f'<LinearRegression '\n",
    "            f'learning_rate={self.learning_rate}>')\n",
    "\n",
    "    def fit(self, X, y, n_iter=1000):\n",
    "        m, n = X.shape\n",
    "        print(f'fitting with m={m} samples with n={n-1} features\\n')\n",
    "        self.beta = np.zeros(shape=(n, 1))\n",
    "        self.costs = []\n",
    "        self.betas = [self.beta]\n",
    "        for iteration in range(n_iter):\n",
    "            y_pred = self.predict(X)\n",
    "            cost = self.cost(y, y_pred, m)\n",
    "            self.costs.append(cost[0][0])\n",
    "            gradient = self.gradient(y, y_pred, X, m)\n",
    "            self.beta = self.beta - (\n",
    "                self.learning_rate * gradient)\n",
    "            self.betas.append(self.beta)\n",
    "\n",
    "    def cost(self, y, y_pred, m):\n",
    "        cost = (1 / (2 * m)) * (y - y_pred).T @ (y - y_pred)\n",
    "        return cost\n",
    "\n",
    "    def gradient(self, y, y_pred, X, m):\n",
    "        gradient = (1 / m) * X.T @ (y_pred - y)\n",
    "        return gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = X @ self.beta\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating linear model instance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<LinearRegression learning_rate=0.05>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting with m=100 samples with n=1 features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### plot the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006930fa376541d6936a89a3c23b2f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'name': 'linear data + noise',\n",
       "              'ty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = fig.add_scatter(\n",
    "    x=X[:,1], \n",
    "    y=linear_regression.predict(X)[:,0],\n",
    "    mode='markers',\n",
    "    name='best fit')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### plot the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_surface(linear_regression):\n",
    "    cost_fig = go.FigureWidget()\n",
    "    cost_fig = cost_fig.add_scatter(\n",
    "        x=list(range(len(linear_regression.costs))),\n",
    "        y=linear_regression.costs,\n",
    "        mode='markers+lines')\n",
    "    cost_fig.layout.title = 'Cost by iteration'\n",
    "    return cost_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd449c4c8c78472cb5ac78f3b0eddf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers+lines',\n",
       "              'type': 'scatter',\n",
       "              'uid': '8…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_fig = plot_surface(linear_regression)\n",
    "cost_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_surface(linear_regression):\n",
    "    beta0s = [beta[0][0] for beta in linear_regression.betas]\n",
    "    beta1s = [beta[1][0] for beta in linear_regression.betas]\n",
    "    beta0_max = max(map(abs, beta0s)) * 1.05\n",
    "    beta1_max = max(map(abs, beta1s)) * 1.05\n",
    "\n",
    "    gradient_descent_fig = go.FigureWidget()\n",
    "    gradient_descent_fig = gradient_descent_fig.add_scatter3d(\n",
    "        x=beta0s,\n",
    "        y=beta1s,\n",
    "        z=linear_regression.costs,\n",
    "        mode='markers+lines',\n",
    "        marker={'size':3, 'color':'red'})\n",
    "\n",
    "    beta0, beta1 = np.meshgrid(\n",
    "        np.linspace(-beta0_max, beta0_max, 100),\n",
    "        np.linspace(-beta1_max, beta1_max, 100))\n",
    "\n",
    "    z = np.diag(\n",
    "        (1 / (2 * m)) * \\\n",
    "        (y - (X @ np.column_stack((beta0.ravel(), beta1.ravel())).T)).T @ \\\n",
    "        (y - (X @ np.column_stack((beta0.ravel(), beta1.ravel())).T))\n",
    "        ).reshape(beta1.shape)\n",
    "\n",
    "    gradient_descent_fig = gradient_descent_fig.add_surface(\n",
    "        x=beta0,\n",
    "        y=beta1,\n",
    "        z=z,\n",
    "        opacity=0.8)\n",
    "    \n",
    "    gradient_descent_fig.layout.title = 'Cost function surface'\n",
    "    gradient_descent_fig.layout.scene.xaxis.title = 'beta0'\n",
    "    gradient_descent_fig.layout.scene.yaxis.title = 'beta1'\n",
    "    gradient_descent_fig.layout.scene.zaxis.title = 'cost' \n",
    "    # cost = average sum square residuals\n",
    "\n",
    "    return gradient_descent_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3aece4a9464436be848df609e40a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'red', 'size': 3},\n",
       "              'mode': 'markers+lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient_descent_fig = plot_surface(linear_regression)\n",
    "gradient_descent_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gradient_descent.html'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.plot(gradient_descent_fig, filename='gradient_descent.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The logistic model aims to predict the discrete y vairable a.k.a the target variable (e.g. whether something will happen) based on a collection of features. It does this by transforming a linear combination of the features into a curve and fitting this curve to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The curve used in logistic regression is the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define y as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y} &= h_{\\boldsymbol{\\beta}}(\\mathbf{x})\\\\\n",
    "\\hat{y}&= \\sigma\\left(\\beta_0x_0+\\cdots+\\beta_nx_n\\right)\\quad &n\\in \\mathbb{N},x_0=1 \\\\\n",
    "\\hat{y}&=\\sigma\\left(\\sum^{n}_{i=0}\\beta_ix_i\\right) \\\\\n",
    "\\hat{y}&=\\sigma\\left(\\mathbf{\\boldsymbol{\\beta}^Tx}\\right)\\quad&\\boldsymbol{\\beta},\\mathbf{x}\\in\\mathbb{R}^{n\\times1}\\\\\n",
    "\\hat{y}&=\\sigma\\left(\\boldsymbol{\\beta}^T\\mathbf{x}\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "notice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\hat{y} = \\frac{1}{1+e^{-\\boldsymbol{\\beta}^T\\mathbf{x}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y} + \\hat{y}e^{\\boldsymbol{\\beta}^T\\mathbf{x}} &= 1\\\\\n",
    "\\hat{y}e^{\\boldsymbol{\\beta}^T\\mathbf{x}} &= 1 - \\hat{y}\\\\\n",
    "\\frac{\\hat{y}}{1 - \\hat{y}} &= e^{\\boldsymbol{\\beta}^T\\mathbf{x}}\\\\\n",
    "\\ln\\left(\\frac{\\hat{y}}{1 - \\hat{y}}\\right)&=\\boldsymbol{\\beta}^T\\mathbf{x}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This above is the logit form of logistic regression. We model the logit as a linear combination of the x variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We define the cost function as follows for each y and corresponding x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "J(\\mathbf{x})\n",
    "&= \\begin{cases}\n",
    "-\\log\\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x})\\right) &\\text{if y=1}\\\\\n",
    "-\\log\\left(1-h_{\\boldsymbol{\\beta}}(\\mathbf{x})\\right) &\\text{if y=0}\\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "J(\\mathbf{x})\n",
    "&= -\\frac{1}{m}\\sum_{j=1}^my^j\\log\\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)\\right)\n",
    "+(1-y^j)\\log\\left(1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)\\right)\\\\\n",
    "&= -\\frac{1}{m}\\sum_{j=1}^my^j\\log\\left(\\frac{1}{1+e^{-\\boldsymbol{\\beta}^T\\mathbf{x}}}\\right)\n",
    "+(1-y^j)\\log\\left(1-\\frac{1}{1+e^{-\\boldsymbol{\\beta}^T\\mathbf{x}}}\\right)\\\\\n",
    "&= -\\frac{1}{m}\\sum_{j=1}^my^j\\log\\left(\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\\right)\n",
    "+(1-y^j)\\log\\left(1-\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)&=\\frac{1}{1+e^{-\\boldsymbol{\\beta}^T\\mathbf{x}^j}}\\\\\n",
    "&=\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial h}{\\partial \\beta_k} &= \\left(1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}\\right)^{-2}e^{-\\sum^{n}_{i=0}\\beta_ix_i} (-x_k^j)\\\\\n",
    "&=\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\frac{e^{-\\sum^{n}_{i=0}\\beta_ix_i} (-x_k^j)}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\\\\\n",
    "&=\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\frac{(1-1+e^{-\\sum^{n}_{i=0}\\beta_ix_i})(-x_k^j)}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\\\\\n",
    "&=\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\left(\n",
    "\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}-\n",
    "\\frac{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\right)(-x_k^j)\\\\\n",
    "&=\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\left(\n",
    "\\frac{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}-\n",
    "\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\right)(x_k^j)\\\\\n",
    "&=\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\left(\n",
    "1-\n",
    "\\frac{1}{1+e^{-\\sum^{n}_{i=0}\\beta_ix_i}}\n",
    "\\right)(x_k^j)\\\\\n",
    "&=h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)(1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j))x_k^j\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to differentiate the cost function i.e. find the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial\\beta_k}\\left(\\boldsymbol{\\beta}\\right) \n",
    "&=\\frac{\\partial}{\\partial\\beta_k}\\left(\n",
    "-\\frac{1}{m}\\sum_{j=1}^my^j\\log\\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)\\right)\n",
    "+(1-y^j)\\log\\left(1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)\\right)\n",
    "\\right)\\\\\n",
    "&=-\\frac{1}{m}\\sum_{j=1}^m\\frac{y^j}{h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)}\\frac{\\partial h}{\\partial \\beta_k}\n",
    "+\\frac{-(1-y^j)}{1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)}\\frac{\\partial h}{\\partial \\beta_k}\\\\\n",
    "&=-\\frac{1}{m}\\sum_{j=1}^m\\frac{y^j}{h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)}\n",
    "h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)(1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j))x_k^j\n",
    "+\\frac{-(1-y^j)}{1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)}\n",
    "h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)(1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j))x_k^j\\\\\n",
    "&=-\\frac{1}{m}\\sum_{j=1}^my^j(1-h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j))x_k^j\n",
    "-(1-y^j)\n",
    "h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)x_k^j\\\\\n",
    "&=\\frac{1}{m}\\sum_{j=1}^m\n",
    "\\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)-y^j\\right)x_k^j\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "hence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\beta}} J\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "       \\frac{\\partial J}{\\partial\\beta_1} \\\\\n",
    "       \\vdots \\\\\n",
    "       \\frac{\\partial J}{\\partial\\beta_n}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "       \\frac{1}{m}\\sum_{j=1}^m\n",
    "            \\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)-y^j\\right)x_1^j\\\\\n",
    "       \\vdots \\\\\n",
    "       \\frac{1}{m}\\sum_{j=1}^m\n",
    "           \\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)-y^j\\right)x_n^j\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define the design matrix and column representation of y. Here each row of X and y are training examples hence there are m rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\\mathbf{X}\\in\\mathbb{R}^{m\\times n},\n",
    "\\quad \\mathbf{y}\\in\\mathbb{R}^{m\\times 1}\n",
    "$$\n",
    "\n",
    "$$\\\\\n",
    "\\mathbf{X}=\\begin{bmatrix}\n",
    "       \\dots & (\\mathbf{x}^1)^T & \\dots\\\\\n",
    "       \\dots & (\\mathbf{x}^2)^T & \\dots\\\\\n",
    "       \\dots & \\vdots  & \\dots\\\\\n",
    "       \\dots & (\\mathbf{x}^m)^T & \\dots\n",
    "\\end{bmatrix}\\quad\n",
    "\\mathbf{y}=\\begin{bmatrix}\n",
    "    y_1\\\\y_2\\\\\\vdots\\\\y_m\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\boldsymbol{\\beta}} J\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "       \\frac{1}{m}\\sum_{j=1}^m\n",
    "            \\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)-y^j\\right)x_1^j\\\\\n",
    "       \\vdots \\\\\n",
    "       \\frac{1}{m}\\sum_{j=1}^m\n",
    "           \\left(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)-y^j\\right)x_n^j\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\frac{1}{m}\n",
    "\\begin{bmatrix}\n",
    "       \\sum^{n}_{i=0}h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)^jx^j_1\\\\\n",
    "       \\vdots \\\\\n",
    "       \\sum^{n}_{i=0}h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j)x^j_n\n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\frac{1}{m}\n",
    "\\begin{bmatrix}\n",
    "       \\sum^{m}_{j=1}y^jx^j_1\\\\\n",
    "       \\vdots \\\\\n",
    "       \\sum^{m}_{j=1}y^jx^j_n\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "h_{\\boldsymbol{\\beta}}(\\mathbf{x}^j) = \\sigma({\\mathbf{x}^j}^T\\boldsymbol{\\beta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\boldsymbol{\\beta}} J\n",
    "&=\\frac{1}{m}\\left(\n",
    "\\mathbf{X}^T\\sigma(\\mathbf{X}\\mathbf{\\boldsymbol{\\beta}})-\\mathbf{X}^T\\mathbf{y}\n",
    "\\right)\\\\\n",
    "&=\\frac{1}{m}\\mathbf{X}^T\\left(\n",
    "\\sigma(\\mathbf{X}\\mathbf{\\boldsymbol{\\beta}})-\\mathbf{y}\n",
    "\\right)\\\\\n",
    "&=\\frac{1}{m}\\mathbf{X}^T\\left(\n",
    "\\mathbf{\\hat{y}}-\\mathbf{y}\n",
    "\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\mathbf{\\hat{y}} = \\sigma(\\mathbf{X}\\mathbf{\\boldsymbol{\\beta}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We could have derived the same thing using matrix calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### example sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The curve used in logistic regression is the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eda80258cba484b98d3d0eddd822217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter',\n",
       "              'uid': '53f53c41-ef72-45d3-adca-5b96c6807a35',\n",
       " …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigmoid_fig = go.FigureWidget()\n",
    "demo_x = np.arange(-10,10,0.1)\n",
    "demo_y = 1 / (1 + np.exp(-demo_x))\n",
    "sigmoid_fig.add_scatter(\n",
    "    x=demo_x,\n",
    "    y=demo_y)\n",
    "sigmoid_fig.layout.title = 'Sigmoid Function'\n",
    "sigmoid_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### make fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = 100\n",
    "x0 = np.ones(shape=(m, 1))\n",
    "x1 = np.linspace(0, 10, m).reshape(-1, 1)\n",
    "X = np.column_stack((x0, x1))\n",
    "\n",
    "# let y = 0.5 * x + 1 + epsilon\n",
    "epsilon =  np.random.normal(scale=2, size=(m, 1))\n",
    "y = x1 + epsilon\n",
    "y = (y > 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1769fb0d694d35bcb046f9c8ba5316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'name': 'linear data + noise',\n",
       "              'ty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget()\n",
    "fig = fig.add_scatter(\n",
    "    x=X[:,1],\n",
    "    y=y[:,0],\n",
    "    mode='markers',\n",
    "    name='linear data + noise')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### graident descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    \n",
    "    def __init__(self, learning_rate=0.05):\n",
    "        self.learning_rate = learning_rate\n",
    "        print('Creating logistic model instance')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f'<LogisticRegression '\n",
    "            f'learning_rate={self.learning_rate}>')\n",
    "\n",
    "    def fit(self, X, y, n_iter=1000):\n",
    "        m, n = X.shape\n",
    "        print(f'fitting with m={m} samples with n={n} features\\n')\n",
    "        self.beta = np.zeros(shape=(n, 1))\n",
    "        self.costs = []\n",
    "        self.betas = [self.beta]\n",
    "        for iteration in range(n_iter):\n",
    "            y_pred = self.predict(X)\n",
    "            cost = (-1 / m) * (\n",
    "                (y.T @ np.log(y_pred)) +\n",
    "                ((np.ones(shape=y.shape) - y).T @ np.log(\n",
    "                    np.ones(shape=y_pred.shape) - y_pred))\n",
    "            )\n",
    "            self.costs.append(cost[0][0])\n",
    "            gradient = (1 / m) * X.T @ (y_pred - y)\n",
    "            self.beta = self.beta - (\n",
    "                self.learning_rate * gradient)\n",
    "            self.betas.append(self.beta)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.sigmoid(X @ self.beta)\n",
    "        return y_pred\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating logistic model instance\n",
      "fitting with m=100 samples with n=2 features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### plot the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4ab4a32fba4236982338b6e4475632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'name': 'linear data + noise',\n",
       "              'ty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = fig.add_scatter(\n",
    "    x=X[:,1], \n",
    "    y=logistic_regression.predict(X)[:,0],\n",
    "    mode='markers',\n",
    "    name='logistic best fit')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### plot the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233b14665e414532a079fc85cfaef446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers+lines',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_fig = plot_surface(logistic_regression)\n",
    "cost_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The k-nearest neighbours algorithm finds k clusters from the data. It does this by starting with k centroids (often randomly selected) and then assigning each point in the data to a cluster based on it's closest centroid. The centroids are then updated as the mean of all points in the cluster. This process is repeated untill the centroids stop changing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Choose k\n",
    "2. randomly select centroids $c_1,\\dots,c_k \\in \\mathbb{R}^n$\n",
    "3. until convergence repeat\n",
    "    * for each $x_i$ assign to cluster $C_j \\in \\{C_1\\dots C_k\\}$ where\n",
    "    $$\n",
    "    j = \\arg\\min_{j}\\sqrt{(x_i - c_j)^2}\n",
    "    $$ \n",
    "    * update each $c_j$ as\n",
    "    $$\n",
    "    c_j = \\frac{1}{|C_j|}\\sum_{x_j\\in C_j}x_j\n",
    "    $$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### make fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_2d_blob(n,x,y,r=1):\n",
    "    x1 = np.random.normal(x, r, n)\n",
    "    y1 = np.random.normal(y, 1 /(1 + abs(x1 - x))**.5, n)\n",
    "    return x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=100\n",
    "xy = np.concatenate((\n",
    "    get_2d_blob(n,1,2,3),\n",
    "    get_2d_blob(n,14,5),\n",
    "    get_2d_blob(n,7,10)\n",
    "),axis=1).T\n",
    "\n",
    "x = xy[:,0]\n",
    "y = xy[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knn_fig = go.FigureWidget()\n",
    "scatter  = go.Scatter(x=x,\n",
    "                      y=y,\n",
    "                      mode='markers',\n",
    "                      name='blob data + noise')\n",
    "knn_fig.add_trace(scatter)\n",
    "iteration = 0\n",
    "knn_fig.layout.title = f'knn Iteration {iteration}'\n",
    "\n",
    "color_mapping={}\n",
    "for i in [1,2,3]:\n",
    "    color_mapping[i] = knn_fig.layout.template.layout.colorway[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4918a683ae4c47008dd5bee45d14a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'name': 'blob data + noise',\n",
       "              'type…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### knn implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4918a683ae4c47008dd5bee45d14a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers',\n",
       "              'name': 'blob data + noise',\n",
       "              'type…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set k and define random centroids\n",
    "k=3\n",
    "c = np.column_stack((\n",
    "    np.random.uniform(x.min(),x.max(),k),\n",
    "    np.random.uniform(y.min(),y.max(),k)))\n",
    "cs = [c]\n",
    "\n",
    "# add the centroids to the fig\n",
    "for i in range(len(c)):\n",
    "    knn_fig.add_scatter(\n",
    "        x=[c[i,0]],\n",
    "        y=[c[i,1]],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            line=dict(width=2,color='DarkSlateGrey')),\n",
    "        text=[f'Centroid-{i}'],\n",
    "        name=f'Centroid-{i}')\n",
    "\n",
    "# Euclidean Distance Caculator\n",
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)\n",
    "\n",
    "def assign_clusters(xy, c):\n",
    "    distances = []\n",
    "    for centroid in c:\n",
    "#         print(centroid)\n",
    "        centorid_distances = dist(xy,centroid)\n",
    "#         print(min(centorid_distances))\n",
    "        distances.append(centorid_distances)\n",
    "    all_distaces = np.array(distances).T\n",
    "    cluster_labels = np.argmin(all_distaces,axis=1)\n",
    "    data_colors = list(map(lambda x: color_mapping[x+1], cluster_labels))\n",
    "    knn_fig.data[0].marker.color = data_colors\n",
    "    return cluster_labels\n",
    "\n",
    "def update_centroids(xy, cluster_labels, cs):\n",
    "    global iteration\n",
    "    c = []\n",
    "    for i in range(3):\n",
    "        centroid = xy[cluster_labels == i,:].mean(axis=0)\n",
    "        knn_fig.data[1+i].x = (centroid[0],)\n",
    "        knn_fig.data[1+i].y = (centroid[1],)\n",
    "        c.append(centroid)\n",
    "    c = np.array(c)\n",
    "    cs.append(c)\n",
    "    iteration +=1\n",
    "    title = f'knn Iteration {iteration}'\n",
    "    knn_fig.layout.title = title\n",
    "    print(f'Change in centroids {dist(cs[-1],cs[-2])}')\n",
    "    return c, cs\n",
    "\n",
    "def update_step():\n",
    "    global xy, c, cs\n",
    "    cluster_labels = assign_clusters(xy, c)\n",
    "    c, cs = update_centroids(xy, cluster_labels, cs)\n",
    "\n",
    "knn_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in centroids [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "update_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
